SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/mnt/yarn/usercache/hadoop/filecache/12/__spark_libs__7847808918427830267.zip/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/02/25 00:53:58 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 10232@ip-172-31-94-11
19/02/25 00:53:58 INFO SignalUtils: Registered signal handler for TERM
19/02/25 00:53:58 INFO SignalUtils: Registered signal handler for HUP
19/02/25 00:53:58 INFO SignalUtils: Registered signal handler for INT
19/02/25 00:53:59 INFO SecurityManager: Changing view acls to: yarn,hadoop
19/02/25 00:53:59 INFO SecurityManager: Changing modify acls to: yarn,hadoop
19/02/25 00:53:59 INFO SecurityManager: Changing view acls groups to: 
19/02/25 00:53:59 INFO SecurityManager: Changing modify acls groups to: 
19/02/25 00:53:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, hadoop); groups with view permissions: Set(); users  with modify permissions: Set(yarn, hadoop); groups with modify permissions: Set()
19/02/25 00:53:59 INFO TransportClientFactory: Successfully created connection to ip-172-31-80-113.ec2.internal/172.31.80.113:40477 after 132 ms (0 ms spent in bootstraps)
19/02/25 00:54:00 INFO SecurityManager: Changing view acls to: yarn,hadoop
19/02/25 00:54:00 INFO SecurityManager: Changing modify acls to: yarn,hadoop
19/02/25 00:54:00 INFO SecurityManager: Changing view acls groups to: 
19/02/25 00:54:00 INFO SecurityManager: Changing modify acls groups to: 
19/02/25 00:54:00 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, hadoop); groups with view permissions: Set(); users  with modify permissions: Set(yarn, hadoop); groups with modify permissions: Set()
19/02/25 00:54:00 INFO TransportClientFactory: Successfully created connection to ip-172-31-80-113.ec2.internal/172.31.80.113:40477 after 3 ms (0 ms spent in bootstraps)
19/02/25 00:54:00 INFO DiskBlockManager: Created local directory at /mnt/yarn/usercache/hadoop/appcache/application_1551054971382_0002/blockmgr-dca1498e-e45f-4caa-bf48-8d4814cc96ec
19/02/25 00:54:00 INFO MemoryStore: MemoryStore started with capacity 2.5 GB
19/02/25 00:54:00 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@ip-172-31-80-113.ec2.internal:40477
19/02/25 00:54:00 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
19/02/25 00:54:00 INFO Executor: Starting executor ID 3 on host ip-172-31-94-11.ec2.internal
19/02/25 00:54:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37759.
19/02/25 00:54:01 INFO NettyBlockTransferService: Server created on ip-172-31-94-11.ec2.internal:37759
19/02/25 00:54:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/02/25 00:54:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(3, ip-172-31-94-11.ec2.internal, 37759, None)
19/02/25 00:54:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(3, ip-172-31-94-11.ec2.internal, 37759, None)
19/02/25 00:54:01 INFO BlockManager: external shuffle service port = 7337
19/02/25 00:54:01 INFO BlockManager: Registering executor with local external shuffle service.
19/02/25 00:54:01 INFO TransportClientFactory: Successfully created connection to ip-172-31-94-11.ec2.internal/172.31.94.11:7337 after 4 ms (0 ms spent in bootstraps)
19/02/25 00:54:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(3, ip-172-31-94-11.ec2.internal, 37759, None)
19/02/25 00:54:01 INFO CoarseGrainedExecutorBackend: Got assigned task 8
19/02/25 00:54:01 INFO CoarseGrainedExecutorBackend: Got assigned task 9
19/02/25 00:54:01 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)
19/02/25 00:54:01 INFO CoarseGrainedExecutorBackend: Got assigned task 10
19/02/25 00:54:01 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
19/02/25 00:54:01 INFO CoarseGrainedExecutorBackend: Got assigned task 11
19/02/25 00:54:01 INFO Executor: Running task 10.0 in stage 0.0 (TID 10)
19/02/25 00:54:01 INFO Executor: Running task 11.0 in stage 0.0 (TID 11)
19/02/25 00:54:01 INFO Executor: Fetching spark://ip-172-31-80-113.ec2.internal:40477/jars/original-spark-demo-1.0.jar with timestamp 1551056009574
19/02/25 00:54:01 INFO TransportClientFactory: Successfully created connection to ip-172-31-80-113.ec2.internal/172.31.80.113:40477 after 13 ms (0 ms spent in bootstraps)
19/02/25 00:54:01 INFO Utils: Fetching spark://ip-172-31-80-113.ec2.internal:40477/jars/original-spark-demo-1.0.jar to /mnt/yarn/usercache/hadoop/appcache/application_1551054971382_0002/spark-8c3501e9-7a95-4e81-a1d6-dddc3ac061ec/fetchFileTemp6013241937862206396.tmp
19/02/25 00:54:01 INFO Utils: Copying /mnt/yarn/usercache/hadoop/appcache/application_1551054971382_0002/spark-8c3501e9-7a95-4e81-a1d6-dddc3ac061ec/2556142661551056009574_cache to /mnt/yarn/usercache/hadoop/appcache/application_1551054971382_0002/container_1551054971382_0002_01_000004/./original-spark-demo-1.0.jar
19/02/25 00:54:01 INFO Executor: Adding file:/mnt/yarn/usercache/hadoop/appcache/application_1551054971382_0002/container_1551054971382_0002_01_000004/./original-spark-demo-1.0.jar to class loader
19/02/25 00:54:01 INFO TorrentBroadcast: Started reading broadcast variable 2
19/02/25 00:54:01 INFO TransportClientFactory: Successfully created connection to ip-172-31-90-64.ec2.internal/172.31.90.64:36855 after 3 ms (0 ms spent in bootstraps)
19/02/25 00:54:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2.5 GB)
19/02/25 00:54:02 INFO TorrentBroadcast: Reading broadcast variable 2 took 279 ms
19/02/25 00:54:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.0 KB, free 2.5 GB)
19/02/25 00:54:02 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:671088640+67108864
19/02/25 00:54:02 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:738197504+67108864
19/02/25 00:54:02 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:536870912+67108864
19/02/25 00:54:02 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:603979776+67108864
19/02/25 00:54:02 INFO TorrentBroadcast: Started reading broadcast variable 0
19/02/25 00:54:02 INFO TransportClientFactory: Successfully created connection to ip-172-31-80-113.ec2.internal/172.31.80.113:33129 after 13 ms (0 ms spent in bootstraps)
19/02/25 00:54:02 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.7 KB, free 2.5 GB)
19/02/25 00:54:02 INFO TorrentBroadcast: Reading broadcast variable 0 took 39 ms
19/02/25 00:54:02 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 317.3 KB, free 2.5 GB)
19/02/25 00:54:03 INFO GPLNativeCodeLoader: Loaded native gpl library
19/02/25 00:54:03 INFO LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev 1546b8dc0ca6f1ffd26a812d52bd7b80915e0a25]
19/02/25 00:54:06 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:54:06 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:54:06 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:54:06 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:54:22 INFO Executor: Finished task 10.0 in stage 0.0 (TID 10). 837 bytes result sent to driver
19/02/25 00:54:22 INFO CoarseGrainedExecutorBackend: Got assigned task 19
19/02/25 00:54:22 INFO Executor: Running task 19.0 in stage 0.0 (TID 19)
19/02/25 00:54:22 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:1275068416+44213409
19/02/25 00:54:22 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 880 bytes result sent to driver
19/02/25 00:54:22 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:54:22 INFO Executor: Finished task 11.0 in stage 0.0 (TID 11). 5983 bytes result sent to driver
19/02/25 00:54:22 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 837 bytes result sent to driver
19/02/25 00:54:25 INFO Executor: Finished task 19.0 in stage 0.0 (TID 19). 837 bytes result sent to driver
19/02/25 00:54:35 INFO CoarseGrainedExecutorBackend: Got assigned task 20
19/02/25 00:54:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 20)
19/02/25 00:54:35 INFO CoarseGrainedExecutorBackend: Got assigned task 23
19/02/25 00:54:35 INFO Executor: Running task 3.0 in stage 1.0 (TID 23)
19/02/25 00:54:35 INFO CoarseGrainedExecutorBackend: Got assigned task 26
19/02/25 00:54:35 INFO CoarseGrainedExecutorBackend: Got assigned task 29
19/02/25 00:54:35 INFO Executor: Running task 6.0 in stage 1.0 (TID 26)
19/02/25 00:54:35 INFO Executor: Running task 9.0 in stage 1.0 (TID 29)
19/02/25 00:54:35 INFO TorrentBroadcast: Started reading broadcast variable 3
19/02/25 00:54:35 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2.5 GB)
19/02/25 00:54:35 INFO TorrentBroadcast: Reading broadcast variable 3 took 23 ms
19/02/25 00:54:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.0 KB, free 2.5 GB)
19/02/25 00:54:35 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:603979776+67108864
19/02/25 00:54:35 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:0+67108864
19/02/25 00:54:35 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:201326592+67108864
19/02/25 00:54:35 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:402653184+67108864
19/02/25 00:54:35 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:54:35 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:54:35 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:54:35 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:54:48 INFO Executor: Finished task 3.0 in stage 1.0 (TID 23). 837 bytes result sent to driver
19/02/25 00:54:48 INFO CoarseGrainedExecutorBackend: Got assigned task 32
19/02/25 00:54:48 INFO Executor: Running task 12.0 in stage 1.0 (TID 32)
19/02/25 00:54:48 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:805306368+67108864
19/02/25 00:54:48 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:54:49 INFO Executor: Finished task 9.0 in stage 1.0 (TID 29). 837 bytes result sent to driver
19/02/25 00:54:49 INFO CoarseGrainedExecutorBackend: Got assigned task 39
19/02/25 00:54:49 INFO Executor: Running task 19.0 in stage 1.0 (TID 39)
19/02/25 00:54:49 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:1275068416+44213409
19/02/25 00:54:49 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:54:49 INFO Executor: Finished task 0.0 in stage 1.0 (TID 20). 3712 bytes result sent to driver
19/02/25 00:54:49 INFO Executor: Finished task 6.0 in stage 1.0 (TID 26). 1371 bytes result sent to driver
19/02/25 00:54:54 INFO Executor: Finished task 19.0 in stage 1.0 (TID 39). 837 bytes result sent to driver
19/02/25 00:54:55 INFO Executor: Finished task 12.0 in stage 1.0 (TID 32). 837 bytes result sent to driver
19/02/25 00:55:57 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
19/02/25 00:55:57 INFO DiskBlockManager: Shutdown hook called
19/02/25 00:55:57 INFO ShutdownHookManager: Shutdown hook called
19/02/25 00:55:57 INFO ShutdownHookManager: Deleting directory /mnt/yarn/usercache/hadoop/appcache/application_1551054971382_0002/spark-8c3501e9-7a95-4e81-a1d6-dddc3ac061ec