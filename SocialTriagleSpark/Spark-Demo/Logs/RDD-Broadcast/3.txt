SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/mnt/yarn/usercache/hadoop/filecache/10/__spark_libs__6942929119226805325.zip/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
19/02/25 00:41:22 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 8942@ip-172-31-90-64
19/02/25 00:41:22 INFO SignalUtils: Registered signal handler for TERM
19/02/25 00:41:22 INFO SignalUtils: Registered signal handler for HUP
19/02/25 00:41:22 INFO SignalUtils: Registered signal handler for INT
19/02/25 00:41:23 INFO SecurityManager: Changing view acls to: yarn,hadoop
19/02/25 00:41:23 INFO SecurityManager: Changing modify acls to: yarn,hadoop
19/02/25 00:41:23 INFO SecurityManager: Changing view acls groups to: 
19/02/25 00:41:23 INFO SecurityManager: Changing modify acls groups to: 
19/02/25 00:41:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, hadoop); groups with view permissions: Set(); users  with modify permissions: Set(yarn, hadoop); groups with modify permissions: Set()
19/02/25 00:41:23 INFO TransportClientFactory: Successfully created connection to ip-172-31-80-113.ec2.internal/172.31.80.113:41381 after 131 ms (0 ms spent in bootstraps)
19/02/25 00:41:23 INFO SecurityManager: Changing view acls to: yarn,hadoop
19/02/25 00:41:23 INFO SecurityManager: Changing modify acls to: yarn,hadoop
19/02/25 00:41:23 INFO SecurityManager: Changing view acls groups to: 
19/02/25 00:41:23 INFO SecurityManager: Changing modify acls groups to: 
19/02/25 00:41:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yarn, hadoop); groups with view permissions: Set(); users  with modify permissions: Set(yarn, hadoop); groups with modify permissions: Set()
19/02/25 00:41:24 INFO TransportClientFactory: Successfully created connection to ip-172-31-80-113.ec2.internal/172.31.80.113:41381 after 7 ms (0 ms spent in bootstraps)
19/02/25 00:41:24 INFO DiskBlockManager: Created local directory at /mnt/yarn/usercache/hadoop/appcache/application_1551054971382_0001/blockmgr-20c6a3f5-b5d4-43e9-8a35-e35f063b1988
19/02/25 00:41:24 INFO MemoryStore: MemoryStore started with capacity 2.5 GB
19/02/25 00:41:24 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@ip-172-31-80-113.ec2.internal:41381
19/02/25 00:41:24 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
19/02/25 00:41:24 INFO Executor: Starting executor ID 2 on host ip-172-31-90-64.ec2.internal
19/02/25 00:41:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43307.
19/02/25 00:41:25 INFO NettyBlockTransferService: Server created on ip-172-31-90-64.ec2.internal:43307
19/02/25 00:41:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/02/25 00:41:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(2, ip-172-31-90-64.ec2.internal, 43307, None)
19/02/25 00:41:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(2, ip-172-31-90-64.ec2.internal, 43307, None)
19/02/25 00:41:25 INFO BlockManager: external shuffle service port = 7337
19/02/25 00:41:25 INFO BlockManager: Registering executor with local external shuffle service.
19/02/25 00:41:25 INFO TransportClientFactory: Successfully created connection to ip-172-31-90-64.ec2.internal/172.31.90.64:7337 after 16 ms (0 ms spent in bootstraps)
19/02/25 00:41:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(2, ip-172-31-90-64.ec2.internal, 43307, None)
19/02/25 00:41:25 INFO CoarseGrainedExecutorBackend: Got assigned task 4
19/02/25 00:41:25 INFO CoarseGrainedExecutorBackend: Got assigned task 5
19/02/25 00:41:25 INFO CoarseGrainedExecutorBackend: Got assigned task 6
19/02/25 00:41:25 INFO CoarseGrainedExecutorBackend: Got assigned task 7
19/02/25 00:41:25 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
19/02/25 00:41:25 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
19/02/25 00:41:25 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
19/02/25 00:41:25 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
19/02/25 00:41:25 INFO Executor: Fetching spark://ip-172-31-80-113.ec2.internal:41381/jars/original-spark-demo-1.0.jar with timestamp 1551055252395
19/02/25 00:41:25 INFO TransportClientFactory: Successfully created connection to ip-172-31-80-113.ec2.internal/172.31.80.113:41381 after 12 ms (0 ms spent in bootstraps)
19/02/25 00:41:25 INFO Utils: Fetching spark://ip-172-31-80-113.ec2.internal:41381/jars/original-spark-demo-1.0.jar to /mnt/yarn/usercache/hadoop/appcache/application_1551054971382_0001/spark-8e29dbd6-edc7-4ec8-b84f-84a59d3f2d39/fetchFileTemp8585177382251331983.tmp
19/02/25 00:41:25 INFO Utils: Copying /mnt/yarn/usercache/hadoop/appcache/application_1551054971382_0001/spark-8e29dbd6-edc7-4ec8-b84f-84a59d3f2d39/-14974240291551055252395_cache to /mnt/yarn/usercache/hadoop/appcache/application_1551054971382_0001/container_1551054971382_0001_01_000003/./original-spark-demo-1.0.jar
19/02/25 00:41:25 INFO Executor: Adding file:/mnt/yarn/usercache/hadoop/appcache/application_1551054971382_0001/container_1551054971382_0001_01_000003/./original-spark-demo-1.0.jar to class loader
19/02/25 00:41:25 INFO TorrentBroadcast: Started reading broadcast variable 1
19/02/25 00:41:26 INFO TransportClientFactory: Successfully created connection to ip-172-31-87-58.ec2.internal/172.31.87.58:37071 after 3 ms (0 ms spent in bootstraps)
19/02/25 00:41:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2.5 GB)
19/02/25 00:41:26 INFO TorrentBroadcast: Reading broadcast variable 1 took 276 ms
19/02/25 00:41:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.0 KB, free 2.5 GB)
19/02/25 00:41:26 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:335544320+67108864
19/02/25 00:41:26 INFO TorrentBroadcast: Started reading broadcast variable 0
19/02/25 00:41:26 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:402653184+67108864
19/02/25 00:41:26 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:268435456+67108864
19/02/25 00:41:26 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:469762048+67108864
19/02/25 00:41:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.7 KB, free 2.5 GB)
19/02/25 00:41:26 INFO TorrentBroadcast: Reading broadcast variable 0 took 25 ms
19/02/25 00:41:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 317.3 KB, free 2.5 GB)
19/02/25 00:41:27 INFO GPLNativeCodeLoader: Loaded native gpl library
19/02/25 00:41:27 INFO LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev 1546b8dc0ca6f1ffd26a812d52bd7b80915e0a25]
19/02/25 00:41:30 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:41:30 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:41:30 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:41:30 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:41:45 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 833 bytes result sent to driver
19/02/25 00:41:45 INFO CoarseGrainedExecutorBackend: Got assigned task 16
19/02/25 00:41:45 INFO Executor: Running task 16.0 in stage 0.0 (TID 16)
19/02/25 00:41:46 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:1073741824+67108864
19/02/25 00:41:46 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:41:46 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 980 bytes result sent to driver
19/02/25 00:41:46 INFO CoarseGrainedExecutorBackend: Got assigned task 19
19/02/25 00:41:46 INFO Executor: Running task 19.0 in stage 0.0 (TID 19)
19/02/25 00:41:46 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:1275068416+44213409
19/02/25 00:41:46 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:41:47 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1868 bytes result sent to driver
19/02/25 00:41:47 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 876 bytes result sent to driver
19/02/25 00:41:52 INFO Executor: Finished task 19.0 in stage 0.0 (TID 19). 833 bytes result sent to driver
19/02/25 00:41:53 INFO Executor: Finished task 16.0 in stage 0.0 (TID 16). 833 bytes result sent to driver
19/02/25 00:41:58 INFO CoarseGrainedExecutorBackend: Got assigned task 21
19/02/25 00:41:58 INFO CoarseGrainedExecutorBackend: Got assigned task 24
19/02/25 00:41:58 INFO Executor: Running task 4.0 in stage 1.0 (TID 24)
19/02/25 00:41:58 INFO TorrentBroadcast: Started reading broadcast variable 3
19/02/25 00:41:58 INFO Executor: Running task 1.0 in stage 1.0 (TID 21)
19/02/25 00:41:58 INFO CoarseGrainedExecutorBackend: Got assigned task 27
19/02/25 00:41:58 INFO Executor: Running task 7.0 in stage 1.0 (TID 27)
19/02/25 00:41:58 INFO CoarseGrainedExecutorBackend: Got assigned task 30
19/02/25 00:41:58 INFO Executor: Running task 10.0 in stage 1.0 (TID 30)
19/02/25 00:41:58 INFO TransportClientFactory: Successfully created connection to ip-172-31-80-113.ec2.internal/172.31.80.113:41467 after 7 ms (0 ms spent in bootstraps)
19/02/25 00:41:58 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2.5 GB)
19/02/25 00:41:58 INFO TorrentBroadcast: Reading broadcast variable 3 took 31 ms
19/02/25 00:41:58 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.0 KB, free 2.5 GB)
19/02/25 00:41:58 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:671088640+67108864
19/02/25 00:41:58 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:469762048+67108864
19/02/25 00:41:58 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:41:58 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:67108864+67108864
19/02/25 00:41:58 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:41:58 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:268435456+67108864
19/02/25 00:41:58 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:41:58 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:42:11 INFO Executor: Finished task 1.0 in stage 1.0 (TID 21). 942 bytes result sent to driver
19/02/25 00:42:11 INFO CoarseGrainedExecutorBackend: Got assigned task 32
19/02/25 00:42:11 INFO Executor: Running task 12.0 in stage 1.0 (TID 32)
19/02/25 00:42:11 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:805306368+67108864
19/02/25 00:42:11 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:42:12 INFO Executor: Finished task 10.0 in stage 1.0 (TID 30). 837 bytes result sent to driver
19/02/25 00:42:12 INFO CoarseGrainedExecutorBackend: Got assigned task 34
19/02/25 00:42:12 INFO Executor: Running task 14.0 in stage 1.0 (TID 34)
19/02/25 00:42:12 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:939524096+67108864
19/02/25 00:42:12 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:42:12 INFO Executor: Finished task 7.0 in stage 1.0 (TID 27). 837 bytes result sent to driver
19/02/25 00:42:12 INFO CoarseGrainedExecutorBackend: Got assigned task 35
19/02/25 00:42:12 INFO Executor: Running task 15.0 in stage 1.0 (TID 35)
19/02/25 00:42:12 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:1006632960+67108864
19/02/25 00:42:12 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:42:12 INFO Executor: Finished task 4.0 in stage 1.0 (TID 24). 837 bytes result sent to driver
19/02/25 00:42:12 INFO CoarseGrainedExecutorBackend: Got assigned task 37
19/02/25 00:42:12 INFO Executor: Running task 17.0 in stage 1.0 (TID 37)
19/02/25 00:42:12 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:1140850688+67108864
19/02/25 00:42:12 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:42:26 INFO Executor: Finished task 15.0 in stage 1.0 (TID 35). 837 bytes result sent to driver
19/02/25 00:42:26 INFO Executor: Finished task 12.0 in stage 1.0 (TID 32). 880 bytes result sent to driver
19/02/25 00:42:26 INFO Executor: Finished task 17.0 in stage 1.0 (TID 37). 837 bytes result sent to driver
19/02/25 00:42:26 INFO Executor: Finished task 14.0 in stage 1.0 (TID 34). 837 bytes result sent to driver
19/02/25 00:42:26 INFO CoarseGrainedExecutorBackend: Got assigned task 41
19/02/25 00:42:26 INFO Executor: Running task 1.0 in stage 2.0 (TID 41)
19/02/25 00:42:26 INFO CoarseGrainedExecutorBackend: Got assigned task 44
19/02/25 00:42:26 INFO Executor: Running task 4.0 in stage 2.0 (TID 44)
19/02/25 00:42:26 INFO CoarseGrainedExecutorBackend: Got assigned task 47
19/02/25 00:42:26 INFO CoarseGrainedExecutorBackend: Got assigned task 50
19/02/25 00:42:26 INFO Executor: Running task 7.0 in stage 2.0 (TID 47)
19/02/25 00:42:26 INFO TorrentBroadcast: Started reading broadcast variable 4
19/02/25 00:42:26 INFO Executor: Running task 10.0 in stage 2.0 (TID 50)
19/02/25 00:42:26 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.3 KB, free 2.5 GB)
19/02/25 00:42:26 INFO TorrentBroadcast: Reading broadcast variable 4 took 15 ms
19/02/25 00:42:26 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.0 KB, free 2.5 GB)
19/02/25 00:42:26 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:469762048+67108864
19/02/25 00:42:26 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:268435456+67108864
19/02/25 00:42:26 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:42:26 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:42:26 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:671088640+67108864
19/02/25 00:42:26 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:42:26 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:67108864+67108864
19/02/25 00:42:26 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:42:40 INFO Executor: Finished task 4.0 in stage 2.0 (TID 44). 837 bytes result sent to driver
19/02/25 00:42:40 INFO CoarseGrainedExecutorBackend: Got assigned task 52
19/02/25 00:42:40 INFO Executor: Running task 12.0 in stage 2.0 (TID 52)
19/02/25 00:42:40 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:805306368+67108864
19/02/25 00:42:40 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:42:40 INFO Executor: Finished task 10.0 in stage 2.0 (TID 50). 837 bytes result sent to driver
19/02/25 00:42:40 INFO CoarseGrainedExecutorBackend: Got assigned task 53
19/02/25 00:42:40 INFO Executor: Running task 13.0 in stage 2.0 (TID 53)
19/02/25 00:42:40 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:872415232+67108864
19/02/25 00:42:40 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:42:40 INFO Executor: Finished task 7.0 in stage 2.0 (TID 47). 837 bytes result sent to driver
19/02/25 00:42:40 INFO CoarseGrainedExecutorBackend: Got assigned task 55
19/02/25 00:42:40 INFO Executor: Running task 15.0 in stage 2.0 (TID 55)
19/02/25 00:42:40 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:1006632960+67108864
19/02/25 00:42:40 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:42:40 INFO Executor: Finished task 1.0 in stage 2.0 (TID 41). 942 bytes result sent to driver
19/02/25 00:42:40 INFO CoarseGrainedExecutorBackend: Got assigned task 56
19/02/25 00:42:40 INFO Executor: Running task 16.0 in stage 2.0 (TID 56)
19/02/25 00:42:40 INFO HadoopRDD: Input split: s3://mr-input/edges.csv:1073741824+67108864
19/02/25 00:42:40 INFO S3NativeFileSystem: Opening 's3://mr-input/edges.csv' for reading
19/02/25 00:42:54 INFO Executor: Finished task 15.0 in stage 2.0 (TID 55). 837 bytes result sent to driver
19/02/25 00:42:54 INFO Executor: Finished task 13.0 in stage 2.0 (TID 53). 837 bytes result sent to driver
19/02/25 00:42:54 INFO Executor: Finished task 16.0 in stage 2.0 (TID 56). 837 bytes result sent to driver
19/02/25 00:42:55 INFO Executor: Finished task 12.0 in stage 2.0 (TID 52). 837 bytes result sent to driver
19/02/25 00:43:56 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
19/02/25 00:43:56 INFO DiskBlockManager: Shutdown hook called
19/02/25 00:43:56 INFO ShutdownHookManager: Shutdown hook called
19/02/25 00:43:56 INFO ShutdownHookManager: Deleting directory /mnt/yarn/usercache/hadoop/appcache/application_1551054971382_0001/spark-8e29dbd6-edc7-4ec8-b84f-84a59d3f2d39